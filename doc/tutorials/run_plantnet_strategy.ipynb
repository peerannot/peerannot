{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pl@ntNet aggregation strategy\n",
    "\n",
    "This aggregation strategy presented in [this paper](https://hal.science/hal-04603038) models the expertise of users the number of labels they correctly interact with.\n",
    "\n",
    "Let us create a toy-dataset to run it with 4 users, 20 items and 9 classes.\n",
    "\n",
    "The full Pl@ntNet-CrowdSWE dataset is available [on zenodo](https://zenodo.org/records/10782465) with more than 6.5M items, 850K users and 11K classes.\n",
    "\n",
    "Each item (*e.g* a plant observation) has been labeled by at least a single user. The ground truth is simulated, so everything is known to measure the accuracy (amongst other metrics). Each item has an authoring user (the picture is taken and uploaded by a user). In the algorithm authoring users and users that vote on others' items are treated differently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import peerannot.models as pmod\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crowdsourced answers (are stored typically in a .json file)\n",
    "votes = {\n",
    "    0: {0: 2, 1: 2, 2: 2},\n",
    "    1: {0: 6, 1: 2, 3: 2},\n",
    "    2: {1: 8, 2: 7, 3: 8},\n",
    "    3: {0: 1, 1: 1, 2: 5},\n",
    "    4: {2: 4},\n",
    "    5: {0: 0, 1: 0, 2: 1, 3: 6},\n",
    "    6: {1: 5, 3: 3},\n",
    "    7: {0: 3, 2: 6, 3: 4},\n",
    "    8: {1: 7, 3: 7},\n",
    "    9: {0: 8, 2: 1, 3: 1},\n",
    "    10: {0: 0, 1: 0, 2: 1},\n",
    "    11: {2: 3},\n",
    "    12: {0: 7, 2: 8, 3: 1},\n",
    "    13: {1: 3},\n",
    "    14: {0: 5, 2: 4, 3: 4},\n",
    "    15: {0: 5, 1: 7},\n",
    "    16: {0: 0, 1: 4, 3: 4},\n",
    "    17: {1: 5, 2: 7, 3: 7},\n",
    "    18: {0: 3},\n",
    "    19: {1: 7, 2: 7},\n",
    "}\n",
    "\n",
    "# Ground truth (gt) and authors of the observations\n",
    "authors = [0, 0, 1, 0, 2, 0, 1, 0, 3, 1, 1, 3, 0, 1, 0, 1, 0, 1, 0, 1]\n",
    "gt = [2, 6, 4, 1, 1, -1, 3, -1, 2, 8, 4, 1, 7, 0, 5, 5, 0, -1, 6, 7]\n",
    "np.savetxt(\"authors_toy.txt\", authors, fmt=\"%i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will evaluate the performance of the method on two subsets:\n",
    "- The full dataset\n",
    "- The subset where the items have been voted on by more than two users \n",
    "We also monitor the proportion of classes retrieved after the aggregation compared to the ground truth (if a class is never predicted by the aggregation, a model can later never be trained to recognize it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mask_more_than_two(answers, gt):\n",
    "    mask = np.zeros(len(answers), dtype=bool)\n",
    "    for tt in tqdm(answers.keys()):\n",
    "        if len(answers[tt]) >= 2 and gt[int(tt)] != -1:\n",
    "            mask[int(tt)] = 1\n",
    "    return mask\n",
    "\n",
    "\n",
    "mask_more_than_two = build_mask_more_than_two(votes, gt)\n",
    "\n",
    "\n",
    "def build_mask_more_than_two(answers, gt):\n",
    "    mask = np.zeros(len(answers), dtype=bool)\n",
    "    for tt in tqdm(answers.keys()):\n",
    "        if len(answers[tt]) >= 2 and gt[int(tt)] != -1:\n",
    "            mask[int(tt)] = 1\n",
    "    return mask\n",
    "\n",
    "\n",
    "mask_more_than_two = build_mask_more_than_two(votes, gt)\n",
    "\n",
    "# %% Metric to compare the strategies where the ground truth is available (proportion of classes kept and accuracy)\n",
    "\n",
    "\n",
    "def vol_class_kept(preds, truth, mask):\n",
    "    uni_test = np.unique(truth[mask])\n",
    "    n_class_test = uni_test.shape[0]\n",
    "    preds_uni = np.unique(preds[mask])\n",
    "    if preds_uni[0] == -1:\n",
    "        preds_uni = preds_uni[1:]\n",
    "    n_class_pred = preds_uni.shape[0]\n",
    "    n_common = len(set(preds_uni).intersection(set(uni_test)))\n",
    "    vol_kept = n_common / n_class_test * 100\n",
    "    return n_class_pred, n_class_test, vol_kept\n",
    "\n",
    "\n",
    "def accuracy(preds, truth, mask):\n",
    "    return np.mean(preds[mask] == truth[mask])\n",
    "\n",
    "\n",
    "# %% Metric to compare the strategies where the ground truth is available (proportion of classes kept and accuracy)\n",
    "\n",
    "\n",
    "def vol_class_kept(preds, truth, mask):\n",
    "    uni_test = np.unique(truth[mask])\n",
    "    n_class_test = uni_test.shape[0]\n",
    "    preds_uni = np.unique(preds[mask])\n",
    "    if preds_uni[0] == -1:\n",
    "        preds_uni = preds_uni[1:]\n",
    "    n_class_pred = preds_uni.shape[0]\n",
    "    n_common = len(set(preds_uni).intersection(set(uni_test)))\n",
    "    vol_kept = n_common / n_class_test * 100\n",
    "    return n_class_pred, n_class_test, vol_kept\n",
    "\n",
    "\n",
    "def accuracy(preds, truth, mask):\n",
    "    return np.mean(preds[mask] == truth[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now run the Pl@ntNet strategy against other strategies available in `peerannot`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each strategy is first instanciated. The `.run` method is called if any optimization procedure is necessary. Estimated labels are recovered with the `.get_answers()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "mv = pmod.MV(answers=votes, n_classes=9, n_workers=4)\n",
    "yhat_mv = mv.get_answers()\n",
    "wawa = pmod.Wawa(answers=votes, n_classes=9, n_workers=4)\n",
    "wawa.run()\n",
    "yhat_wawa = wawa.get_answers()\n",
    "twothird = pmod.TwoThird(answers=votes, n_classes=9, n_workers=4)\n",
    "yhat_twothird = twothird.get_answers()\n",
    "\n",
    "# %% run the PlantNet aggregatio\n",
    "pn = pmod.PlantNet(\n",
    "    answers=votes,\n",
    "    n_classes=9,\n",
    "    n_workers=4,\n",
    "    alpha=0.5,\n",
    "    beta=0.2,\n",
    "    authors=\"authors_toy.txt\",\n",
    ")\n",
    "pn.run(maxiter=5, epsilon=1e-9)\n",
    "yhatpn = pn.get_answers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we plot the metrics considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %% Compute the metrics for each strategy\n",
    "res_full = []\n",
    "res_more_than_two = []\n",
    "vol_class_full = []\n",
    "vol_class_more_than_two = []\n",
    "\n",
    "gt = np.array(gt)\n",
    "strats = [\"MV\", \"WAWA\", \"TwoThird\", \"PlantNet\"]\n",
    "\n",
    "for strat, res in zip(strats, [yhat_mv, yhat_wawa, yhat_twothird, yhatpn]):\n",
    "    res_full.append(accuracy(res, gt, np.ones(len(gt), dtype=bool)))\n",
    "    vol_class_full.append(vol_class_kept(res, gt, np.ones(len(gt), dtype=bool))[2])\n",
    "    res_more_than_two.append(accuracy(res, gt, mask_more_than_two))\n",
    "    vol_class_more_than_two.append(vol_class_kept(res, gt, mask_more_than_two)[2])\n",
    "# %% Plot the accuracy against the proportion of classes kept\n",
    "plt.figure()\n",
    "for i, strat in enumerate(strats):\n",
    "    plt.scatter(vol_class_full[i], res_full[i], label=strat)\n",
    "plt.title(r\"Full dataset\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Proportion of classes kept (%)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "for i, strat in enumerate(strats):\n",
    "    plt.scatter(vol_class_more_than_two[i], res_more_than_two[i], label=strat)\n",
    "plt.title(r\"Dataset with at least 2 annotations per observation\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Proportion of classes kept (%)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
